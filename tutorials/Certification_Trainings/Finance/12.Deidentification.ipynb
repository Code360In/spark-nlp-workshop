{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7f2c545-14d6-41da-a4cc-0dc8a6ea3180",
   "metadata": {},
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb2ac5e3-fe7c-4431-bb24-3c48649be54b",
   "metadata": {},
   "source": [
    "# Financial Deidentification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8053010f-fd6f-4224-ba3b-3d009befe3bd",
   "metadata": {},
   "source": [
    "## Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "643947a2-2500-45f7-b903-4ef3b0e9adaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import os\n",
    "license_key = \"/home/jovyan/work/shared/gokhan/keys/4.0.2.spark_nlp_for_healthcare .json\"\n",
    "\n",
    "with open(license_key) as f:\n",
    "    license_keys = json.load(f)\n",
    "    \n",
    "locals().update(license_keys)\n",
    "\n",
    "# Adding license key-value pairs to environment variables\n",
    "os.environ.update(license_keys)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43b19455-ec9a-4f3e-8748-d25127ee9503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparknlp version: 4.0.2\n",
      "sparknlp_jsl version: 4.0.2\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "print(\"sparknlp version:\",sparknlp.version())\n",
    "print(\"sparknlp_jsl version:\", sparknlp_jsl.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2cf3afe-5da1-45cd-8499-2a7956abb825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/jovyan/.ivy2/cache\n",
      "The jars for the packages stored in: /home/jovyan/.ivy2/jars\n",
      ":: loading settings :: url = jar:file:/home/jovyan/work/shared/venvs/gokhan/lib/python3.8/site-packages/pyspark/jars/ivy-2.4.0.jar!/org/apache/ivy/core/settings/ivysettings.xml\n",
      "com.johnsnowlabs.nlp#spark-nlp_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-0a60d814-0822-43a9-a3cd-36d210aa75bf;1.0\n",
      "\tconfs: [default]\n",
      "\tfound com.johnsnowlabs.nlp#spark-nlp_2.12;4.0.2 in central\n",
      "\tfound com.typesafe#config;1.4.2 in central\n",
      "\tfound org.rocksdb#rocksdbjni;6.29.5 in central\n",
      "\tfound com.amazonaws#aws-java-sdk-bundle;1.11.828 in central\n",
      "\tfound com.github.universal-automata#liblevenshtein;3.0.0 in central\n",
      "\tfound com.google.code.findbugs#annotations;3.0.1 in central\n",
      "\tfound net.jcip#jcip-annotations;1.0 in central\n",
      "\tfound com.google.code.findbugs#jsr305;3.0.1 in central\n",
      "\tfound com.google.protobuf#protobuf-java-util;3.0.0-beta-3 in central\n",
      "\tfound com.google.protobuf#protobuf-java;3.0.0-beta-3 in central\n",
      "\tfound com.google.code.gson#gson;2.3 in central\n",
      "\tfound it.unimi.dsi#fastutil;7.0.12 in central\n",
      "\tfound org.projectlombok#lombok;1.16.8 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.21 in central\n",
      "\tfound com.navigamez#greex;1.0 in central\n",
      "\tfound dk.brics.automaton#automaton;1.11-8 in central\n",
      "\tfound com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 in central\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/spark-nlp_2.12/4.0.2/spark-nlp_2.12-4.0.2.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#spark-nlp_2.12;4.0.2!spark-nlp_2.12.jar (767ms)\n",
      "downloading https://repo1.maven.org/maven2/com/typesafe/config/1.4.2/config-1.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.typesafe#config;1.4.2!config.jar(bundle) (8ms)\n",
      "downloading https://repo1.maven.org/maven2/org/rocksdb/rocksdbjni/6.29.5/rocksdbjni-6.29.5.jar ...\n",
      "\t[SUCCESSFUL ] org.rocksdb#rocksdbjni;6.29.5!rocksdbjni.jar (506ms)\n",
      "downloading https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk-bundle/1.11.828/aws-java-sdk-bundle-1.11.828.jar ...\n",
      "\t[SUCCESSFUL ] com.amazonaws#aws-java-sdk-bundle;1.11.828!aws-java-sdk-bundle.jar (1344ms)\n",
      "downloading https://repo1.maven.org/maven2/com/johnsnowlabs/nlp/tensorflow-cpu_2.12/0.4.2/tensorflow-cpu_2.12-0.4.2.jar ...\n",
      "\t[SUCCESSFUL ] com.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2!tensorflow-cpu_2.12.jar (1979ms)\n",
      ":: resolution report :: resolve 1813ms :: artifacts dl 4619ms\n",
      "\t:: modules in use:\n",
      "\tcom.amazonaws#aws-java-sdk-bundle;1.11.828 from central in [default]\n",
      "\tcom.github.universal-automata#liblevenshtein;3.0.0 from central in [default]\n",
      "\tcom.google.code.findbugs#annotations;3.0.1 from central in [default]\n",
      "\tcom.google.code.findbugs#jsr305;3.0.1 from central in [default]\n",
      "\tcom.google.code.gson#gson;2.3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java;3.0.0-beta-3 from central in [default]\n",
      "\tcom.google.protobuf#protobuf-java-util;3.0.0-beta-3 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#spark-nlp_2.12;4.0.2 from central in [default]\n",
      "\tcom.johnsnowlabs.nlp#tensorflow-cpu_2.12;0.4.2 from central in [default]\n",
      "\tcom.navigamez#greex;1.0 from central in [default]\n",
      "\tcom.typesafe#config;1.4.2 from central in [default]\n",
      "\tdk.brics.automaton#automaton;1.11-8 from central in [default]\n",
      "\tit.unimi.dsi#fastutil;7.0.12 from central in [default]\n",
      "\tnet.jcip#jcip-annotations;1.0 from central in [default]\n",
      "\torg.projectlombok#lombok;1.16.8 from central in [default]\n",
      "\torg.rocksdb#rocksdbjni;6.29.5 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.21 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   17  |   5   |   5   |   0   ||   17  |   5   |\n",
      "\t---------------------------------------------------------------------\n",
      "\n",
      ":: problems summary ::\n",
      ":::: ERRORS\n",
      "\tSERVER ERROR: Bad Gateway url=https://dl.bintray.com/spark-packages/maven/com/amazonaws/aws-java-sdk-pom/1.11.828/aws-java-sdk-pom-1.11.828.jar\n",
      "\n",
      "\n",
      ":: USE VERBOSE OR DEBUG MESSAGE LEVEL FOR MORE DETAILS\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-0a60d814-0822-43a9-a3cd-36d210aa75bf\n",
      "\tconfs: [default]\n",
      "\t17 artifacts copied, 0 already retrieved (572114kB/346ms)\n",
      "22/08/21 18:13:09 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sparknlp version: 4.0.2\n",
      "sparknlp_jsl version: 4.0.2\n"
     ]
    }
   ],
   "source": [
    "import sparknlp\n",
    "\n",
    "#spark = sparknlp.start(gpu = True) # for GPU training >> sparknlp.start(gpu = True) # for Spark 2.3 =>> sparknlp.start(spark23 = True)\n",
    "import json\n",
    "import os\n",
    "\n",
    "import sparknlp\n",
    "import sparknlp_jsl\n",
    "\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from sparknlp_jsl.annotator import *\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.ml import Pipeline,PipelineModel\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.ml import Pipeline\n",
    "import pandas as pd\n",
    "import os\n",
    "import pandas as pd, csv, numpy as np, re\n",
    "from sparknlp.training import CoNLL\n",
    "import pyspark.sql.functions as F\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from sparknlp.training import CoNLL\n",
    "import re\n",
    "import copy\n",
    "from faker import Faker\n",
    "import random\n",
    "\n",
    "\n",
    "spark = sparknlp_jsl.start(license_keys['SECRET'])\n",
    "print(\"sparknlp version:\",sparknlp.version())\n",
    "print(\"sparknlp_jsl version:\", sparknlp_jsl.version())\n",
    "builder = SparkSession.builder \\\n",
    ".appName(\"Spark NLP Licensed\") \\\n",
    ".master(\"local[*]\") \\\n",
    ".config(\"spark.driver.memory\", \"54G\")\\\n",
    ".config(\"spark.executor.heartbeatInterval\", \"60s\")\\\n",
    ".config(\"spark.executor.memory\", \"6G\")\\\n",
    ".config(\"spark.driver.maxResultSize\", \"8G\")\\\n",
    ".config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    ".config(\"spark.kryoserializer.buffer.max\", \"2000M\") \\\n",
    ".config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:\"+ PUBLIC_VERSION) \\\n",
    ".config(\"spark.jars\", \"https://pypi.johnsnowlabs.com/\"+ SECRET +\"/spark-nlp-jsl-\"+JSL_VERSION+\".jar\")\n",
    "spark = builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c5c1990-1e00-4141-8825-5e9e75d402ad",
   "metadata": {},
   "source": [
    "# Deidentification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124c01da-b9a9-4327-a46b-f09d1d89d893",
   "metadata": {},
   "source": [
    "Some financial information can be considered sensitive. (e.g.,document, organization, address, signer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc92df9a-8ede-4db3-80b9-be1e713f45d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "[ | ]sentence_detector_dl download started this may take some time.\n",
      "Approximate size to download 514.9 KB\n",
      "Download done! Loading the resource.\n",
      "[OK!]\n",
      "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
      "Approximate size to download 447.2 MB\n",
      "[ | ]roberta_embeddings_legal_roberta_base download started this may take some time.\n",
      "Approximate size to download 447.2 MB\n",
      "[ | ]Download done! Loading the resource.\n",
      "[ / ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetectorDLModel.pretrained(\"sentence_detector_dl\",\"xx\")\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "    #.setCustomBounds([\"\\n\\n\"])\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "fin_ner = MedicalNerModel.load(\"./medicalner_parties/outputs/1/cuad_ner\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\") \n",
    "    #.setLabelCasing(\"upper\")\n",
    "\n",
    "ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setReplaceLabels({\"ALIAS\": \"PARTY\"}) # Replace \"ALIAS\" entity as \"PARTY\"\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      embeddings,\n",
    "      fin_ner,\n",
    "      ner_converter])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddb9087-f3d2-4b14-89ad-507e3910e889",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pretrained NER models extracts:\n",
    "- Document\n",
    "- Date\n",
    "- Party (Organization Name)\n",
    "- Alias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f594290b-6ea9-47a2-9515-76faed5ab63c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['O',\n",
       " 'I-DOC',\n",
       " 'B-EFFDATE',\n",
       " 'B-ALIAS',\n",
       " 'I-ALIAS',\n",
       " 'B-PARTY',\n",
       " 'I-EFFDATE',\n",
       " 'B-DOC',\n",
       " 'I-PARTY']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_ner.getClasses()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5f5fbf4b-ad6c-4042-8fff-4b6082aeed5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Form of Indenture between the Company and Wells Fargo Bank , as trustee - incorporated by reference to Exhibit 4.3 to the Company's Registration Statement on Form S-3 , filed on August 28, 2015 \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd9d648-81ec-46fa-aa02-20506f0ba7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3fa9c519-347f-4f63-8f32-b240526ab42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = result.select(F.explode(F.arrays_zip(result.token.result, \n",
    "                                                 result.ner.result)).alias(\"cols\")) \\\n",
    "                  .select(F.expr(\"cols['0']\").alias(\"token\"),\n",
    "                          F.expr(\"cols['1']\").alias(\"ner_label\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3df21455-9650-4d3d-8b11-8380a0883121",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 17:================================>                     (119 + 4) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|ner_label|count|\n",
      "+---------+-----+\n",
      "|O        |27   |\n",
      "|I-EFFDATE|3    |\n",
      "|I-PARTY  |2    |\n",
      "|B-PARTY  |1    |\n",
      "|B-ALIAS  |1    |\n",
      "|B-EFFDATE|1    |\n",
      "+---------+-----+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result_df.select(\"token\", \"ner_label\").groupBy('ner_label').count().orderBy('count', ascending=False).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba982823-16d8-477d-9a47-d41d9087523d",
   "metadata": {},
   "source": [
    "### Check extracted sensitive entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8e766d87-e1f2-49e3-afe2-f7d0d7703e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------+\n",
      "|chunk           |ner_label|\n",
      "+----------------+---------+\n",
      "|Company         |PARTY    |\n",
      "|Wells Fargo Bank|PARTY    |\n",
      "|August 28, 2015 |EFFDATE  |\n",
      "+----------------+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                     result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cccf04f-6630-4f8c-96af-f5b7e35c119d",
   "metadata": {},
   "source": [
    "## Masking and Obfuscation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4648bf0-9c6e-49b3-9080-7bb3551e1675",
   "metadata": {},
   "source": [
    "### Replace these enitites with Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7ac54e-46d5-4a9b-a74b-3859a283ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_converter = NerConverterInternal()\\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "      .setOutputCol(\"ner_chunk\") \n",
    "\n",
    "deidentification = DeIdentification() \\\n",
    "      .setInputCols([\"sentence\", \"token\", \"ner_chunk\"]) \\\n",
    "      .setOutputCol(\"deidentified\") \\\n",
    "      .setMode(\"mask\")\\\n",
    "      .setReturnEntityMappings(True) #  return a new column to save the mappings between the mask/obfuscated entities and original entities.\n",
    "      #.setMappingsColumn(\"MappingCol\") # change the name of the column, 'aux' is default\n",
    "\n",
    "deidPipeline = Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      embeddings,\n",
    "      fin_ner,\n",
    "      ner_converter,\n",
    "      deidentification])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model_deid = deidPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf417b51-c6d0-44b3-ac80-43da90300247",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model_deid.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bf8f80c-4277-4302-8993-a0f88311b66f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|        deidentified|                 aux|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Form of Indenture...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 3, Fo...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 30, 36, ...|[[document, 0, 17...|[[chunk, 30, 36, ...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a8892001-1392-4bc2-ab92-81d565c9d996",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Form of Indenture between the Company and Well...</td>\n",
       "      <td>Form of Indenture between the &lt;ALIAS&gt; and &lt;PAR...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Form of Indenture between the Company and Well...   \n",
       "\n",
       "                                        deidentified  \n",
       "0  Form of Indenture between the <ALIAS> and <PAR...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip(result.sentence.result, result.deidentified.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7f7662-6fb7-4ad6-b7a8-aa9587dafc85",
   "metadata": {},
   "source": [
    "We have three modes to mask the entities in the Deidentification annotator. You can select the modes using the `.setMaskingPolicy()` parameter. The methods are the followings:\n",
    "\n",
    "**“entity_labels”**: Mask with the entity type of that chunk. (default) <br/>\n",
    "**“same_length_chars”**: Mask the deid entities with same length of asterix ( * ) with brackets ( [ , ] ) on both end. <br/>\n",
    "**“fixed_length_chars”**: Mask the deid entities with a fixed length of asterix ( * ). The length is setting up using the `setFixedMaskLength()` method. <br/>\n",
    "\n",
    "Let's try each of these and compare the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2294859f-933e-4675-a573-bc67c7dc7ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#deid model with \"entity_labels\"\n",
    "deid_entity_labels= DeIdentification()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
    "    .setOutputCol(\"deid_entity_label\")\\\n",
    "    .setMode(\"mask\")\\\n",
    "    .setReturnEntityMappings(True)\\\n",
    "    .setMaskingPolicy(\"entity_labels\")\n",
    "\n",
    "#deid model with \"same_length_chars\"\n",
    "deid_same_length= DeIdentification()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
    "    .setOutputCol(\"deid_same_length\")\\\n",
    "    .setMode(\"mask\")\\\n",
    "    .setReturnEntityMappings(True)\\\n",
    "    .setMaskingPolicy(\"same_length_chars\")\n",
    "\n",
    "#deid model with \"fixed_length_chars\"\n",
    "deid_fixed_length= DeIdentification()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_chunk\"])\\\n",
    "    .setOutputCol(\"deid_fixed_length\")\\\n",
    "    .setMode(\"mask\")\\\n",
    "    .setReturnEntityMappings(True)\\\n",
    "    .setMaskingPolicy(\"fixed_length_chars\")\\\n",
    "    .setFixedMaskLength(4)\n",
    "\n",
    "\n",
    "deidPipeline = Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      embeddings,\n",
    "      fin_ner,\n",
    "      ner_converter,\n",
    "      deid_entity_labels,\n",
    "      deid_same_length,\n",
    "      deid_fixed_length])\n",
    "\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "model_deid = deidPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a5d82d09-b920-45e3-8856-cbb3a43697af",
   "metadata": {},
   "outputs": [],
   "source": [
    "policy_result = model_deid.transform(spark.createDataFrame([[text]]).toDF(\"text\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d94fccb3-8874-428e-8cf3-2ed1bf443002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|   deid_entity_label|                 aux|    deid_same_length|   deid_fixed_length|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Form of Indenture...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 3, Fo...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 30, 36, ...|[[document, 0, 17...|[[chunk, 30, 33, ...|[[document, 0, 19...|[[document, 0, 16...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "policy_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f759241e-63a1-47ef-a562-a0a0272ed0e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deid_entity_label</th>\n",
       "      <th>deid_same_length</th>\n",
       "      <th>deid_fixed_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Form of Indenture between the Company and Well...</td>\n",
       "      <td>Form of Indenture between the &lt;ALIAS&gt; and &lt;PAR...</td>\n",
       "      <td>Form of Indenture between the [*****] and [***...</td>\n",
       "      <td>Form of Indenture between the **** and **** , ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  Form of Indenture between the Company and Well...   \n",
       "\n",
       "                                   deid_entity_label  \\\n",
       "0  Form of Indenture between the <ALIAS> and <PAR...   \n",
       "\n",
       "                                    deid_same_length  \\\n",
       "0  Form of Indenture between the [*****] and [***...   \n",
       "\n",
       "                                   deid_fixed_length  \n",
       "0  Form of Indenture between the **** and **** , ...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "policy_result.select(F.explode(F.arrays_zip(policy_result.sentence.result, \n",
    "                                            policy_result.deid_entity_label.result, \n",
    "                                            policy_result.deid_same_length.result, \n",
    "                                            policy_result.deid_fixed_length.result)).alias(\"cols\")) \\\n",
    "             .select(F.expr(\"cols['0']\").alias(\"sentence\"),\n",
    "                     F.expr(\"cols['1']\").alias(\"deid_entity_label\"),\n",
    "                     F.expr(\"cols['2']\").alias(\"deid_same_length\"),\n",
    "                     F.expr(\"cols['3']\").alias(\"deid_fixed_length\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ad89cd-3022-46df-b4a1-6f6d90d0445a",
   "metadata": {},
   "source": [
    "### Mapping Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "941bfa77-2a19-4d47-ace2-0d5c6eb66514",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|aux                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              |\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[[chunk, 30, 36, <ALIAS>, [originalChunk -> Company, chunk -> 0, beginOriginalChunk -> 30, confidence -> 0.4453, ner_source -> ner_chunk, entity -> ALIAS, endOriginalChunk -> 36, sentence -> 0], []], [chunk, 42, 48, <PARTY>, [originalChunk -> Wells Fargo Bank, chunk -> 1, beginOriginalChunk -> 42, confidence -> 0.7543333, ner_source -> ner_chunk, entity -> PARTY, endOriginalChunk -> 57, sentence -> 0], []], [chunk, 169, 177, <EFFDATE>, [originalChunk -> August 28, 2015, chunk -> 2, beginOriginalChunk -> 178, confidence -> 0.9278, ner_source -> ner_chunk, entity -> EFFDATE, endOriginalChunk -> 192, sentence -> 0], []]]|\n",
      "+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(\"aux\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ea4502c9-ae7b-4bf0-97ec-0ed7a6ba2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+----------+--------+---------+----------+--------+\n",
      "|chunk           |beginChunk|endChunk|label    |beginLabel|endLabel|\n",
      "+----------------+----------+--------+---------+----------+--------+\n",
      "|Company         |30        |36      |<ALIAS>  |30        |36      |\n",
      "|Wells Fargo Bank|42        |57      |<PARTY>  |42        |48      |\n",
      "|August 28, 2015 |178       |192     |<EFFDATE>|169       |177     |\n",
      "+----------------+----------+--------+---------+----------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip(result.aux.metadata, \n",
    "                                     result.aux.result, \n",
    "                                     result.aux.begin, \n",
    "                                     result.aux.end)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']['originalChunk']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['0']['beginOriginalChunk']\").alias(\"beginChunk\"),\n",
    "              F.expr(\"cols['0']['endOriginalChunk']\").alias(\"endChunk\"),\n",
    "              F.expr(\"cols['1']\").alias(\"label\"),\n",
    "              F.expr(\"cols['2']\").alias(\"beginLabel\"),\n",
    "              F.expr(\"cols['3']\").alias(\"endLabel\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9673cfe-a13e-4099-bb22-30084ec4cf3b",
   "metadata": {},
   "source": [
    "## Reidentification\n",
    "\n",
    "We can use `ReIdentification` annotator to go back to the original sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a1ce1bf-2c4f-4bf9-b0d9-84f8fefcfb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "reIdentification = ReIdentification()\\\n",
    "    .setInputCols([\"aux\",\"deidentified\"])\\\n",
    "    .setOutputCol(\"original\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e0467f8-87dd-424b-b4c0-25fae1cb1b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "reid_result = reIdentification.transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80a4f86b-bb67-4fc2-8686-146770a50f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|        deidentified|                 aux|            original|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|Form of Indenture...|[[document, 0, 19...|[[document, 0, 19...|[[token, 0, 3, Fo...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 30, 36, ...|[[document, 0, 17...|[[chunk, 30, 36, ...|[[document, 0, 19...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reid_result.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3a8e7d3-9cfd-4ad0-a129-e350a9669c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Form of Indenture between the Company and Wells Fargo Bank , as trustee - incorporated by reference to Exhibit 4.3 to the Company's Registration Statement on Form S-3 , filed on August 28, 2015 \n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|result                                                                                                                                                                                             |\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "|[Form of Indenture between the Company and Wells Fargo Bank , as trustee - incorporated by reference to Exhibit 4.3 to the Company's Registration Statement on Form S-3 , filed on August 28, 2015]|\n",
      "+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(text)\n",
    "\n",
    "reid_result.select('original.result').show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d5c012-0eef-48a5-9d3d-915e942f5639",
   "metadata": {},
   "source": [
    "## Using multiple NER in the same pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b11381f-af80-49e7-9d30-418a753fa08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roberta_embeddings_legal_roberta_base download started this may take some time.\n",
      "Approximate size to download 447.2 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "documentAssembler = DocumentAssembler()\\\n",
    "    .setInputCol(\"text\")\\\n",
    "    .setOutputCol(\"document\")\n",
    "\n",
    "sentenceDetector = SentenceDetector()\\\n",
    "    .setInputCols([\"document\"])\\\n",
    "    .setOutputCol(\"sentence\")\n",
    "\n",
    "tokenizer = Tokenizer()\\\n",
    "    .setInputCols([\"sentence\"])\\\n",
    "    .setOutputCol(\"token\")\n",
    "\n",
    "embeddings = RoBertaEmbeddings.pretrained(\"roberta_embeddings_legal_roberta_base\",\"en\") \\\n",
    "    .setInputCols([\"sentence\", \"token\"]) \\\n",
    "    .setOutputCol(\"embeddings\")\n",
    "\n",
    "fin_ner = MedicalNerModel.load(\"./medicalner_parties/outputs/1/cuad_ner\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner\") \n",
    "    #.setLabelCasing(\"upper\")\n",
    "\n",
    "ner_converter = NerConverterInternal() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner\"])\\\n",
    "    .setOutputCol(\"ner_chunk\")\\\n",
    "    .setReplaceLabels({\"ALIAS\": \"PARTY\"})\n",
    "\n",
    "ner_signers = MedicalNerModel.load(\"./medicalner_signers_cur/outputs/1c/cuad_ner\") \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"embeddings\"]) \\\n",
    "    .setOutputCol(\"ner_signers\") \n",
    "    #.setLabelCasing(\"upper\")\n",
    "\n",
    "ner_converter_signers = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_signers\"]) \\\n",
    "    .setOutputCol(\"ner_signer_chunk\")\n",
    "\n",
    "chunk_merge = ChunkMergeApproach()\\\n",
    "    .setInputCols(\"ner_signer_chunk\", \"ner_chunk\")\\\n",
    "    .setOutputCol(\"deid_merged_chunk\")\n",
    "\n",
    "deidentification = DeIdentification() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"deid_merged_chunk\"]) \\\n",
    "    .setOutputCol(\"deidentified\") \\\n",
    "    .setMode(\"mask\")\\\n",
    "    .setIgnoreRegex(True)\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      embeddings,\n",
    "      fin_ner,\n",
    "      ner_converter,\n",
    "      ner_signers,\n",
    "      ner_converter_signers,\n",
    "      chunk_merge,\n",
    "      deidentification])\n",
    "\n",
    "empty_data = spark.createDataFrame([[\"\"]]).toDF(\"text\")\n",
    "\n",
    "model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8f4ef972-ad0c-4297-896a-94b639027810",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\" ENTIRE AGREEMENT. Commvault Systems, Inc. , Name of each exchange on which registered\n",
    "Common Stock, $0.01 par value\n",
    "CVLT\n",
    "The NASDAQ Stock Market\n",
    "By : Sherly Johnson.   \"\"\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "63fe74f9-768c-47c1-87e0-86d7a2a556bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+---------+\n",
      "|chunk                 |ner_label|\n",
      "+----------------------+---------+\n",
      "|ENTIRE AGREEMENT      |DOC      |\n",
      "|Commvault Systems, Inc|PARTY    |\n",
      "+----------------------+---------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
    "\n",
    "# fin_ner\n",
    "result.select(F.explode(F.arrays_zip(result.ner_chunk.result, \n",
    "                                     result.ner_chunk.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3256773b-3371-4af4-a4e3-34e2c818640c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------+\n",
      "|chunk                 |ner_label     |\n",
      "+----------------------+--------------+\n",
      "|Commvault Systems, Inc|PARTY         |\n",
      "|Sherly Johnson        |SIGNING_PERSON|\n",
      "+----------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
    "\n",
    "# ner_signers\n",
    "result.select(F.explode(F.arrays_zip(result.ner_signer_chunk.result, \n",
    "                                     result.ner_signer_chunk.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4a899327-42d8-48c1-ab4a-5f692b10be22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+--------------+\n",
      "|chunk                 |ner_label     |\n",
      "+----------------------+--------------+\n",
      "|ENTIRE AGREEMENT      |DOC           |\n",
      "|Commvault Systems, Inc|PARTY         |\n",
      "|Sherly Johnson        |SIGNING_PERSON|\n",
      "+----------------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
    "\n",
    "# merged_chunk\n",
    "result.select(F.explode(F.arrays_zip(result.deid_merged_chunk.result, \n",
    "                                     result.deid_merged_chunk.metadata)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"chunk\"),\n",
    "              F.expr(\"cols['1']['entity']\").alias(\"ner_label\")).show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6c21ec8-5e6a-4bb4-b0bd-d7aa14fb6fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENTIRE AGREEMENT.</td>\n",
       "      <td>&lt;DOC&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commvault Systems, Inc.</td>\n",
       "      <td>&lt;PARTY&gt;.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>, Name of each exchange on which registered\\nC...</td>\n",
       "      <td>, Name of each exchange on which registered\\nC...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0                                  ENTIRE AGREEMENT.   \n",
       "1                            Commvault Systems, Inc.   \n",
       "2  , Name of each exchange on which registered\\nC...   \n",
       "\n",
       "                                        deidentified  \n",
       "0                                             <DOC>.  \n",
       "1                                           <PARTY>.  \n",
       "2  , Name of each exchange on which registered\\nC...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.select(F.explode(F.arrays_zip(result.sentence.result, \n",
    "                                     result.deidentified.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"sentence\"),\n",
    "              F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de79296-97f8-4daa-940c-1fd8d176c8c3",
   "metadata": {},
   "source": [
    "## Obfuscation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e7c83b-780b-4d3e-be7f-604cd310babd",
   "metadata": {},
   "source": [
    "In the obfuscation mode **DeIdentificationModel** will replace sensitive entities with random values of the same type. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "31b20c5a-bc56-43e1-9101-6503c23ab49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the obfuscation dict for the new entities\n",
    "obs_lines = \"\"\"CTO#SIGNING_TITLE\n",
    "Project Manager#SIGNING_TITLE\n",
    "Sales Manager#SIGNING_TITLE\n",
    "Business Manager#SIGNING_TITLE\n",
    "Coordinator#SIGNING_TITLE\n",
    "Officer#SIGNING_TITLE\n",
    "Legal Agreement#DOC\n",
    "Contract#DOC\n",
    "Estate Document#DOC\n",
    "official Document#DOC\n",
    "Deed of Covenant#DOC\n",
    "TURER INC#PARTY\n",
    "Clark llc.#PARTY\n",
    "SESA CO.#PARTY\n",
    "John Snow Labs Inc#PARTY\n",
    "MGT Trust Company, LLC.#PARTY\n",
    "JAMES TURNER#SIGNING_PERSON\n",
    "Juan Garcia#SIGNING_PERSON\n",
    "Benjamin Dean#SIGNING_PERSON\n",
    "Tommy Lee#SIGNING_PERSON\n",
    "Dorothy Keen#SIGNING_PERSON\n",
    "(\"AGREEMENT\")#ALIAS\n",
    "(\"TRADE COMPANY\")#ALIAS\n",
    "(the\" Agreement\")#ALIAS\n",
    "(\"private company\")#ALIAS\n",
    "(the \"Contract\")#ALIAS\n",
    "26-06-1990#EFFDATE\n",
    "03/08/2025#EFFDATE\n",
    "01/01/2045#EFFDATE\n",
    "11/7/2016#EFFDATE\n",
    "12-12-2022#EFFDATE \"\"\"\n",
    "\n",
    "with open ('obfuscate.txt', 'w') as f:\n",
    "    f.write(obs_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "210db7c7-e1a3-46ac-941f-160abc068ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_converter_signers = NerConverter() \\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_signers\"]) \\\n",
    "    .setOutputCol(\"ner_signer_chunk\")\n",
    "\n",
    "chunk_merge = ChunkMergeApproach()\\\n",
    "    .setInputCols(\"ner_signer_chunk\", \"ner_chunk\")\\\n",
    "    .setOutputCol(\"deid_merged_chunk\")\n",
    "\n",
    "obfuscation = DeIdentification()\\\n",
    "    .setInputCols([\"sentence\", \"token\", \"ner_signer_chunk\"]) \\\n",
    "    .setOutputCol(\"deidentified\") \\\n",
    "    .setMode(\"obfuscate\")\\\n",
    "    .setObfuscateDate(True)\\\n",
    "    .setObfuscateRefFile('obfuscate.txt')\\\n",
    "    .setObfuscateRefSource(\"both\") #default: \"faker\"\n",
    "\n",
    "\n",
    "nlpPipeline = Pipeline(stages=[\n",
    "      documentAssembler, \n",
    "      sentenceDetector,\n",
    "      tokenizer,\n",
    "      embeddings,\n",
    "      fin_ner,\n",
    "      ner_converter,\n",
    "      ner_signers,\n",
    "      ner_converter_signers,\n",
    "      chunk_merge,\n",
    "      obfuscation])\n",
    "\n",
    "obfuscation_model = nlpPipeline.fit(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "38268201-7202-462e-b195-59709e7fdc8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"We have acquired businesses and technology in the past. For example, we acquired CNL Software Limited and RedSky . \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0264dd21-5927-46b3-82f3-575d7a0b7a16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>deidentified</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>We have acquired businesses and technology in ...</td>\n",
       "      <td>We have acquired businesses and technology in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>For example, we acquired CNL Software Limited ...</td>\n",
       "      <td>For example, we acquired MGT Trust Company, LL...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  We have acquired businesses and technology in ...   \n",
       "1  For example, we acquired CNL Software Limited ...   \n",
       "\n",
       "                                        deidentified  \n",
       "0  We have acquired businesses and technology in ...  \n",
       "1  For example, we acquired MGT Trust Company, LL...  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = obfuscation_model.transform(spark.createDataFrame([[text]]).toDF(\"text\"))\n",
    "\n",
    "result.select(F.explode(F.arrays_zip(result.sentence.result, result.deidentified.result)).alias(\"cols\")) \\\n",
    "      .select(F.expr(\"cols['0']\").alias(\"sentence\"), F.expr(\"cols['1']\").alias(\"deidentified\")).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd5940-8389-4acb-b505-6dab2eebbbb3",
   "metadata": {},
   "source": [
    "## Use full pipeline in the Light model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "79bba6fc-b913-4e23-b6e1-315616756073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We have acquired businesses and technology in the past.',\n",
       " 'For example, we acquired <PARTY> and <PARTY> .']"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_model = LightPipeline(model)\n",
    "annotated_text = light_model.annotate(text)\n",
    "annotated_text['deidentified']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "9f0c3c9f-b7b6-4e68-ae5d-9c8833bf06d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['We have acquired businesses and technology in the past.',\n",
       " 'For example, we acquired MGT Trust Company, LLC. and John Snow Labs Inc .']"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obf_light_model = LightPipeline(obfuscation_model)\n",
    "annotated_text = obf_light_model.annotate(text)\n",
    "annotated_text['deidentified']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5ac615-13af-4149-bf78-96e2d27d9c5f",
   "metadata": {},
   "source": [
    "# Save the Pipeline and Use it from Your Local"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "f54386d7-486c-44e9-9557-954c45d9d493",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.write().overwrite().save('pipeline_deid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "2a6de84f-d5da-405a-afe6-7d3840dd454d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "deid_pipeline = PretrainedPipeline.from_disk(\"pipeline_deid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cbd89eeb-f5f5-4639-9ccf-29c2491f4d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = spark.createDataFrame([[text]]).toDF(\"text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "e78dea29-7a4c-4724-8e2f-93e635c2602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_aa9603bd4664,\n",
       " SentenceDetector_9dfc07b9925a,\n",
       " REGEX_TOKENIZER_51409ee6ff79,\n",
       " ROBERTA_EMBEDDINGS_b915dff90901,\n",
       " MedicalNerModel_f714c7246b46,\n",
       " NER_CONVERTER_ea35cc068eef,\n",
       " MedicalNerModel_2b2f0f671f99,\n",
       " NerConverter_ee04fb1570a2,\n",
       " MERGE_8323f467d068,\n",
       " DE-IDENTIFICATION_0858e305ee72]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_pipeline.model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "de7e48e9-4433-40c8-8e88-a5d5a0265bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 187:======================================>                  (2 + 1) / 3]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|                text|            document|            sentence|               token|          embeddings|                 ner|           ner_chunk|         ner_signers|    ner_signer_chunk|   deid_merged_chunk|        deidentified|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "|We have acquired ...|[[document, 0, 11...|[[document, 0, 54...|[[token, 0, 1, We...|[[word_embeddings...|[[named_entity, 0...|[[chunk, 81, 100,...|[[named_entity, 0...|[[chunk, 81, 100,...|[[chunk, 81, 100,...|[[document, 0, 54...|\n",
      "+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "deid_pipeline.model.transform(data).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615a3cf3-ae62-40cf-b9b2-a68c8053c908",
   "metadata": {},
   "source": [
    "# Pretrained Deidentification Pipeline\n",
    "\n",
    "We have this pipeline can be used to deidentify financial information from texts.The financial information will be masked and obfuscated in the resulting text. The pipeline can mask and obfuscate `DOC`, `EFFDATE`, `PARTY`, `ALIAS`, `SIGNING_PERSON`, `SIGNING_TITLE`, `COUNTRY`, `CITY`, `STATE`, `STREET`, `ZIP`, `EMAIL`, `FAX`, `LOCATION-OTHER`, `DATE`,`PHONE` entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "994c32d7-44e7-4637-9f64-454af9168dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sparknlp.pretrained import PretrainedPipeline\n",
    "\n",
    "deid_pipeline = PretrainedPipeline.from_disk(\"finpipe_deid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "a09f14d8-54d9-4ed9-a7c4-6074f421020a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DocumentAssembler_57ba7ce8bff9,\n",
       " SentenceDetectorDLModel_8aaebf7e098e,\n",
       " REGEX_TOKENIZER_2f265bb3f6b5,\n",
       " ROBERTA_EMBEDDINGS_b915dff90901,\n",
       " BERT_EMBEDDINGS_29ce72cd673e,\n",
       " MedicalNerModel_f714c7246b46,\n",
       " NerConverter_5a5bb98a24c7,\n",
       " MedicalNerModel_2b2f0f671f99,\n",
       " NerConverter_8b80797c7f67,\n",
       " MedicalNerModel_7b3b98b32784,\n",
       " NER_CONVERTER_fb28b23bc35d,\n",
       " MedicalNerModel_419e708135cb,\n",
       " NER_CONVERTER_af60235365b4,\n",
       " CONTEXTUAL-PARSER_85a13a5ff4bd,\n",
       " CONTEXTUAL-PARSER_bf8f02fb6658,\n",
       " REGEX_MATCHER_6199c32417bc,\n",
       " REGEX_MATCHER_2d694c8416b8,\n",
       " MERGE_5b96d578aa9b,\n",
       " DE-IDENTIFICATION_3d3dd57f734a,\n",
       " DE-IDENTIFICATION_471d94c72cd0,\n",
       " DE-IDENTIFICATION_29cac8c6cf56,\n",
       " DE-IDENTIFICATION_407b57c7d657,\n",
       " Finisher_ed29d709e530]"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_pipeline.model.stages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "00a6b038-7178-4fe3-b7f6-664bad53ff92",
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"\"\" REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF\n",
    "Commvault Systems, Inc.  \n",
    "(Exact name of registrant as specified in its charter) \n",
    "Signed By : Sherly Johnson\n",
    "(Address of principal executive offices, including zip code) \n",
    "(732) 870-4000\n",
    "(telephone number, including area code) \n",
    "Name of each exchange on which registered\n",
    "CVLT\n",
    "The NASDAQ Stock Market\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bd76c039-f1bb-4839-a2c5-9b5715629700",
   "metadata": {},
   "outputs": [],
   "source": [
    "deid_res= deid_pipeline.annotate(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "84add88b-9686-4fcc-83fa-6f64465f4aff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['obfuscated', 'deidentified', 'masked_fixed_length_chars', 'deid_merged_chunk', 'sentence', 'masked_with_chars'])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "deid_res.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "9551bf51-c2e4-4d7c-968e-1c75bd43f888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Masked</th>\n",
       "      <th>Masked with Chars</th>\n",
       "      <th>Masked with Fixed Chars</th>\n",
       "      <th>Obfuscated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF</td>\n",
       "      <td>REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF</td>\n",
       "      <td>REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF</td>\n",
       "      <td>REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF</td>\n",
       "      <td>REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Commvault Systems, Inc.  \\n(Exact name of registrant as specified in its charter)</td>\n",
       "      <td>&lt;PARTY&gt;  \\n(Exact name of registrant as specified in its charter)</td>\n",
       "      <td>[*********************]  \\n(Exact name of registrant as specified in its charter)</td>\n",
       "      <td>****  \\n(Exact name of registrant as specified in its charter)</td>\n",
       "      <td>John Snow Labs Inc  \\n(Exact name of registrant as specified in its charter)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Signed By : Sherly Johnson</td>\n",
       "      <td>Signed By : &lt;SIGNING_PERSON&gt;</td>\n",
       "      <td>Signed By : [************]</td>\n",
       "      <td>Signed By : ****</td>\n",
       "      <td>Signed By : Dorothy Keen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Address of principal executive offices, including zip code) \\n(732) 870-4000\\n(telephone number...</td>\n",
       "      <td>(Address of principal executive offices, including zip code) \\n&lt;PHONE&gt;\\n(telephone number, inclu...</td>\n",
       "      <td>(Address of principal executive offices, including zip code) \\n[************]\\n(telephone number...</td>\n",
       "      <td>(Address of principal executive offices, including zip code) \\n****\\n(telephone number, includin...</td>\n",
       "      <td>(Address of principal executive offices, including zip code) \\n031460 3797\\n(telephone number, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Name of each exchange on which registered</td>\n",
       "      <td>Name of each exchange on which registered</td>\n",
       "      <td>Name of each exchange on which registered</td>\n",
       "      <td>Name of each exchange on which registered</td>\n",
       "      <td>Name of each exchange on which registered</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CVLT</td>\n",
       "      <td>&lt;PARTY&gt;</td>\n",
       "      <td>[**]</td>\n",
       "      <td>****</td>\n",
       "      <td>TURER INC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The NASDAQ Stock Market</td>\n",
       "      <td>The &lt;PARTY&gt;</td>\n",
       "      <td>The [*****************]</td>\n",
       "      <td>The ****</td>\n",
       "      <td>The TURER INC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                              Sentence  \\\n",
       "0                             REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF   \n",
       "1                    Commvault Systems, Inc.  \\n(Exact name of registrant as specified in its charter)   \n",
       "2                                                                           Signed By : Sherly Johnson   \n",
       "3  (Address of principal executive offices, including zip code) \\n(732) 870-4000\\n(telephone number...   \n",
       "4                                                            Name of each exchange on which registered   \n",
       "5                                                                                                 CVLT   \n",
       "6                                                                              The NASDAQ Stock Market   \n",
       "\n",
       "                                                                                                Masked  \\\n",
       "0                             REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF   \n",
       "1                                    <PARTY>  \\n(Exact name of registrant as specified in its charter)   \n",
       "2                                                                         Signed By : <SIGNING_PERSON>   \n",
       "3  (Address of principal executive offices, including zip code) \\n<PHONE>\\n(telephone number, inclu...   \n",
       "4                                                            Name of each exchange on which registered   \n",
       "5                                                                                              <PARTY>   \n",
       "6                                                                                          The <PARTY>   \n",
       "\n",
       "                                                                                     Masked with Chars  \\\n",
       "0                             REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF   \n",
       "1                    [*********************]  \\n(Exact name of registrant as specified in its charter)   \n",
       "2                                                                           Signed By : [************]   \n",
       "3  (Address of principal executive offices, including zip code) \\n[************]\\n(telephone number...   \n",
       "4                                                            Name of each exchange on which registered   \n",
       "5                                                                                                 [**]   \n",
       "6                                                                              The [*****************]   \n",
       "\n",
       "                                                                               Masked with Fixed Chars  \\\n",
       "0                             REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF   \n",
       "1                                       ****  \\n(Exact name of registrant as specified in its charter)   \n",
       "2                                                                                     Signed By : ****   \n",
       "3  (Address of principal executive offices, including zip code) \\n****\\n(telephone number, includin...   \n",
       "4                                                            Name of each exchange on which registered   \n",
       "5                                                                                                 ****   \n",
       "6                                                                                             The ****   \n",
       "\n",
       "                                                                                            Obfuscated  \n",
       "0                             REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF  \n",
       "1                         John Snow Labs Inc  \\n(Exact name of registrant as specified in its charter)  \n",
       "2                                                                             Signed By : Dorothy Keen  \n",
       "3  (Address of principal executive offices, including zip code) \\n031460 3797\\n(telephone number, i...  \n",
       "4                                                            Name of each exchange on which registered  \n",
       "5                                                                                            TURER INC  \n",
       "6                                                                                        The TURER INC  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 100)\n",
    "\n",
    "df= pd.DataFrame(list(zip(deid_res[\"sentence\"], \n",
    "                          deid_res[\"deidentified\"],\n",
    "                          deid_res[\"masked_with_chars\"],\n",
    "                          deid_res[\"masked_fixed_length_chars\"], \n",
    "                          deid_res[\"obfuscated\"])),\n",
    "                 columns= [\"Sentence\", \"Masked\", \"Masked with Chars\", \"Masked with Fixed Chars\", \"Obfuscated\"])\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gokhan",
   "language": "python",
   "name": "gokhan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
