{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sXatvRX899i0"
      },
      "source": [
        "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44B_JtXmyOuF"
      },
      "source": [
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/5.Text_Classification_with_ClassifierDL.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kl6fW8Fkf3vN"
      },
      "source": [
        "# 5 Text Classification with ClassifierDL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUAgkEOqOnJh"
      },
      "source": [
        "**Relevant blogpost:** https://towardsdatascience.com/text-classification-in-spark-nlp-with-bert-and-universal-sentence-encoders-e644d618ca32"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06DMedvcgjKa"
      },
      "source": [
        "## Colab Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eVtGC-AUPfEN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738ef193-4580-49d7-c51b-7256345acaa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-08-24 17:48:45--  https://setup.johnsnowlabs.com/colab.sh\n",
            "Resolving setup.johnsnowlabs.com (setup.johnsnowlabs.com)... 51.158.130.125\n",
            "Connecting to setup.johnsnowlabs.com (setup.johnsnowlabs.com)|51.158.130.125|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh [following]\n",
            "--2022-08-24 17:48:46--  https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp/master/scripts/colab_setup.sh\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1191 (1.2K) [text/plain]\n",
            "Saving to: ‘STDOUT’\n",
            "\n",
            "-                   100%[===================>]   1.16K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-08-24 17:48:46 (67.4 MB/s) - written to stdout [1191/1191]\n",
            "\n",
            "Installing PySpark 3.2.1 and Spark NLP 4.0.1\n",
            "setup Colab for PySpark 3.2.1 and Spark NLP 4.0.1\n",
            "Upgrading libcudnn8 to 8.1.0 for GPU\n",
            "\u001b[K     |████████████████████████████████| 281.4 MB 41 kB/s \n",
            "\u001b[K     |████████████████████████████████| 531 kB 60.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 198 kB 74.3 MB/s \n",
            "\u001b[?25h  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.2.1 -s 4.0.1 -g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "id": "KjcBNzFVgoky",
        "outputId": "1c1f9cdb-bdda-4463-bfe5-e78556cf295c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Spark NLP version 4.0.1\n",
            "Apache Spark version: 3.2.1\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f9b94a4e610>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://6abc62cbf1e4:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.2.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local[*]</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark NLP</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import sparknlp\n",
        "\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from pyspark.ml import Pipeline\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "spark = sparknlp.start(gpu = True)# for GPU training >> sparknlp.start(gpu = True)\n",
        "\n",
        "print(\"Spark NLP version\", sparknlp.version())\n",
        "print(\"Apache Spark version:\", spark.version)\n",
        "\n",
        "spark"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_zW6ZKxb0h_x"
      },
      "source": [
        "<b><h1><font color='darkred'>!!! WARNING !!! </font><h1><b>\n",
        "\n",
        "\n",
        "\n",
        "**If you get an error related to Java port not found 55, it is probably because that the Colab memory cannot handle the model and the Spark session died. In that case, try on a larger machine or restart the kernel at the top and then come back here and rerun.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o3qkiSEaWENr"
      },
      "source": [
        "## ClassiferDL with Word Embeddings and Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VTK1AsahOpz"
      },
      "source": [
        "### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fEYijaovgw3M"
      },
      "outputs": [],
      "source": [
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_train.csv\n",
        "! wget -q https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp-workshop/master/tutorials/Certification_Trainings/Public/data/news_category_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0u9cOqqhS4w",
        "outputId": "69b6df64-6004-4e2d-d70b-6ee2d8a8a0d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 24948\n",
            "-rw-r--r-- 1 root root  1504408 Aug 24 17:51 news_category_test.csv\n",
            "-rw-r--r-- 1 root root 24032125 Aug 24 17:51 news_category_train.csv\n",
            "drwxr-xr-x 1 root root     4096 Aug 15 13:44 sample_data\n"
          ]
        }
      ],
      "source": [
        "!ls -lt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoTE46WThUz2",
        "outputId": "820db824-50ed-4eb7-e6d7-a1ac55c787f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------+\n",
            "|category|                                       description|\n",
            "+--------+--------------------------------------------------+\n",
            "|Business| Short sellers, Wall Street's dwindling band of...|\n",
            "|Business| Private investment firm Carlyle Group, which h...|\n",
            "|Business| Soaring crude prices plus worries about the ec...|\n",
            "|Business| Authorities have halted oil export flows from ...|\n",
            "|Business| Tearaway world oil prices, toppling records an...|\n",
            "|Business| Stocks ended slightly higher on Friday but sta...|\n",
            "|Business| Assets of the nation's retail money market mut...|\n",
            "|Business| Retail sales bounced back a bit in July, and n...|\n",
            "|Business|\" After earning a PH.D. in Sociology, Danny Baz...|\n",
            "|Business| Short sellers, Wall Street's dwindling  band o...|\n",
            "|Business| Soaring crude prices plus worries  about the e...|\n",
            "|Business| OPEC can do nothing to douse scorching  oil pr...|\n",
            "|Business| Non OPEC oil exporters should consider  increa...|\n",
            "|Business| WASHINGTON/NEW YORK (Reuters) - The auction fo...|\n",
            "|Business| The dollar tumbled broadly on Friday  after da...|\n",
            "|Business|If you think you may need to help your elderly ...|\n",
            "|Business|The purchasing power of kids is a big part of w...|\n",
            "|Business|There is little cause for celebration in the st...|\n",
            "|Business|The US trade deficit has exploded 19 to a recor...|\n",
            "|Business|Oil giant Shell could be bracing itself for a t...|\n",
            "+--------+--------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_train.csv\")\n",
        "\n",
        "trainDataset.show(truncate=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3iINSk1hc2E",
        "outputId": "d5e65a3f-8c7d-4348-99fc-6f34715d5100"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "120000"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "trainDataset.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEaUJ3xzhgLf",
        "outputId": "0066f16e-ec8f-4fe2-b8a2-80767cd447c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World|30000|\n",
            "|Sci/Tech|30000|\n",
            "|  Sports|30000|\n",
            "|Business|30000|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "trainDataset.groupBy(\"category\") \\\n",
        "    .count() \\\n",
        "    .orderBy(col(\"count\").desc()) \\\n",
        "    .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Mk82Fnkhj4N",
        "outputId": "3a6c3f21-9628-4b6e-d439-8b5c4477b77b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+-----+\n",
            "|category|count|\n",
            "+--------+-----+\n",
            "|   World| 1900|\n",
            "|Sci/Tech| 1900|\n",
            "|  Sports| 1900|\n",
            "|Business| 1900|\n",
            "+--------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"news_category_test.csv\")\n",
        "\n",
        "\n",
        "testDataset.groupBy(\"category\") \\\n",
        "      .count() \\\n",
        "      .orderBy(col(\"count\").desc()) \\\n",
        "      .show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0nHTo9Fxjjwq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "cb0764f0-df05-4f95-b3e1-1922110b5aaa"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n(trainingData, testData) = trainDataset.randomSplit([0.7, 0.3], seed = 100)\\nprint(\"Training Dataset Count: \" + str(trainingData.count()))\\nprint(\"Test Dataset Count: \" + str(testData.count()))\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# if we want to split the dataset\n",
        "'''\n",
        "(trainingData, testData) = trainDataset.randomSplit([0.7, 0.3], seed = 100)\n",
        "print(\"Training Dataset Count: \" + str(trainingData.count()))\n",
        "print(\"Test Dataset Count: \" + str(testData.count()))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AkxJDshietW",
        "outputId": "bd4cd645-801c-414d-9761-718e30b0efa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "lemma_antbnc download started this may take some time.\n",
            "Approximate size to download 907.6 KB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"description\") \\\n",
        "    .setOutputCol(\"document\")\n",
        "    \n",
        "tokenizer = Tokenizer() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"token\")\n",
        "      \n",
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"token\"]) \\\n",
        "    .setOutputCol(\"normalized\")\n",
        "\n",
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "    .setInputCols(\"normalized\")\\\n",
        "    .setOutputCol(\"cleanTokens\")\\\n",
        "    .setCaseSensitive(False)\n",
        "\n",
        "lemma = LemmatizerModel.pretrained('lemma_antbnc') \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"lemma\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QX-LjXhvY2EV"
      },
      "source": [
        "### with Glove 100d embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6PJxX4JY1S-",
        "outputId": "4de63a37-b931-4720-e1ca-a884c7c01f7f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "glove_100d download started this may take some time.\n",
            "Approximate size to download 145.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "glove_embeddings = WordEmbeddingsModel().pretrained() \\\n",
        "      .setInputCols([\"document\",'lemma'])\\\n",
        "      .setOutputCol(\"embeddings\")\\\n",
        "      .setCaseSensitive(False)\n",
        "\n",
        "embeddingsSentence = SentenceEmbeddings() \\\n",
        "      .setInputCols([\"document\", \"embeddings\"]) \\\n",
        "      .setOutputCol(\"sentence_embeddings\") \\\n",
        "      .setPoolingStrategy(\"AVERAGE\")\n",
        "\n",
        "classsifierdl = ClassifierDLApproach()\\\n",
        "      .setInputCols([\"sentence_embeddings\"])\\\n",
        "      .setOutputCol(\"class\")\\\n",
        "      .setLabelColumn(\"category\")\\\n",
        "      .setMaxEpochs(3)\\\n",
        "      .setEnableOutputLogs(True)\n",
        "      #.setOutputLogsPath('logs')\n",
        "\n",
        "clf_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            tokenizer,\n",
        "            normalizer,\n",
        "            stopwords_cleaner, \n",
        "            lemma, \n",
        "            glove_embeddings,\n",
        "            embeddingsSentence,\n",
        "            classsifierdl])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "L0lwLD_hZkrI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "496e9ee7-d7ed-47da-b908-48f292861560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndefault classifierDL params:\\n\\n    maxEpochs -> 10,\\n    lr -> 5e-3f,\\n    dropout -> 0.5f,\\n    batchSize -> 64,\\n    enableOutputLogs -> false,\\n    verbose -> Verbose.Silent.id,\\n    validationSplit -> 0.0f,\\n    outputLogsPath -> \"\"\\n    \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "'''\n",
        "default classifierDL params:\n",
        "\n",
        "    maxEpochs -> 10,\n",
        "    lr -> 5e-3f,\n",
        "    dropout -> 0.5f,\n",
        "    batchSize -> 64,\n",
        "    enableOutputLogs -> false,\n",
        "    verbose -> Verbose.Silent.id,\n",
        "    validationSplit -> 0.0f,\n",
        "    outputLogsPath -> \"\"\n",
        "    \n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QKnwlFNi2A6",
        "outputId": "40a96965-32bb-4788-d893-d2e521a21966"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 764 ms, sys: 87.8 ms, total: 852 ms\n",
            "Wall time: 2min 25s\n"
          ]
        }
      ],
      "source": [
        "# Train (3 min for 3 epochs)\n",
        "%%time\n",
        "\n",
        "clf_pipelineModel = clf_pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "693tFCxy9gQ8",
        "outputId": "ea33e4ca-e5ab-436a-98a9-e5ac86404784"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 3 - learning_rate: 0.005 - batch_size: 64 - training_examples: 120000 - classes: 4\n",
            "Epoch 0/3 - 7.25s - loss: 1638.4495 - acc: 0.8685 - batches: 1875\n",
            "Epoch 1/3 - 4.73s - loss: 1618.0045 - acc: 0.8809083 - batches: 1875\n",
            "Epoch 2/3 - 4.23s - loss: 1611.3066 - acc: 0.885825 - batches: 1875\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "log_file_name = os.listdir(\"/root/annotator_logs\")[0]\n",
        "\n",
        "with open(\"/root/annotator_logs/\"+log_file_name, \"r\") as log_file :\n",
        "    print(log_file.read())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "GvJDn6C6j8BK"
      },
      "outputs": [],
      "source": [
        "# get the predictions on test Set\n",
        "\n",
        "preds = clf_pipelineModel.transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5XdH8Z3ljYpx",
        "outputId": "97e8996c-8eff-4f15-8298-cbb006c334e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "|category|                                                                     description|    result|\n",
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "|Business|Unions representing workers at Turner   Newall say they are 'disappointed' af...|[Business]|\n",
            "|Sci/Tech| TORONTO, Canada    A second team of rocketeers competing for the  #36;10 mil...|[Sci/Tech]|\n",
            "|Sci/Tech| A company founded by a chemistry researcher at the University of Louisville ...|[Sci/Tech]|\n",
            "|Sci/Tech| It's barely dawn when Mike Fitzpatrick starts his shift with a blur of color...|[Sci/Tech]|\n",
            "|Sci/Tech| Southern California's smog fighting agency went after emissions of the bovin...|[Sci/Tech]|\n",
            "|Sci/Tech|\"The British Department for Education and Skills (DfES) recently launched a \"...|[Sci/Tech]|\n",
            "|Sci/Tech|\"confessed author of the Netsky and Sasser viruses, is responsible for 70 per...|[Sci/Tech]|\n",
            "|Sci/Tech|\\\\FOAF/LOAF  and bloom filters have a lot of interesting properties for socia...|[Sci/Tech]|\n",
            "|Sci/Tech|\"Wiltshire Police warns about \"\"phishing\"\" after its fraud squad chief was ta...|[Sci/Tech]|\n",
            "|Sci/Tech|In its first two years, the UK's dedicated card fraud unit, has recovered 36,...|[Sci/Tech]|\n",
            "+--------+--------------------------------------------------------------------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "preds.select('category','description',\"class.result\").show(10, truncate=80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "AZh8gMZEk0Dy"
      },
      "outputs": [],
      "source": [
        "preds_df = preds.select('category','description',\"class.result\").toPandas()\n",
        "\n",
        "# The result is an array since in Spark NLP you can have multiple sentences.\n",
        "# Let's explode the array and get the item(s) inside of result column out\n",
        "preds_df['result'] = preds_df['result'].apply(lambda x : x[0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VqF8O6ilB__",
        "outputId": "d6b1283d-b3eb-49c1-b46b-63b88022463d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Business       0.83      0.83      0.83      1900\n",
            "    Sci/Tech       0.84      0.86      0.85      1900\n",
            "      Sports       0.93      0.97      0.95      1900\n",
            "       World       0.92      0.86      0.89      1900\n",
            "\n",
            "    accuracy                           0.88      7600\n",
            "   macro avg       0.88      0.88      0.88      7600\n",
            "weighted avg       0.88      0.88      0.88      7600\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# We are going to use sklearn to evalute the results on test dataset\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print (classification_report(preds_df['category'], preds_df['result']))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9tXlaLYpwdG"
      },
      "source": [
        "## Getting prediction from Trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "iNERYucrncR5"
      },
      "outputs": [],
      "source": [
        "from sparknlp.base import LightPipeline\n",
        "\n",
        "light_model = LightPipeline(clf_pipelineModel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBztNjY14FKn",
        "outputId": "7f3d56af-0c2f-4f63-ce97-d6eb87a9c27b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(description=\"Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"),\n",
              " Row(description=' TORONTO, Canada    A second team of rocketeers competing for the  #36;10 million Ansari X Prize, a contest for privately funded suborbital space flight, has officially announced the first launch date for its manned rocket.')]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "testDataset.select('description').take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lDlkv_Af4Ie8",
        "outputId": "2689111c-b72b-462c-d43c-a3b205704e52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Business']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "text='''\n",
        "Fearing the fate of Italy, the centre-right government has threatened to be merciless with those who flout tough restrictions. \n",
        "As of Wednesday it will also include all shops being closed across Greece, with the exception of supermarkets. Banks, pharmacies, pet-stores, mobile phone stores, opticians, bakers, mini-markets, couriers and food delivery outlets are among the few that will also be allowed to remain open.\n",
        "'''\n",
        "result = light_model.annotate(text)\n",
        "\n",
        "result['class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3OTJAYq4MwR",
        "outputId": "b4a62dcf-8ec5-4726-9df9-6711bb8ff02a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'lemma': ['soccer', 'game', 'postpone'],\n",
              " 'document': ['the soccer games will be postponed.'],\n",
              " 'normalized': ['the', 'soccer', 'games', 'will', 'be', 'postponed'],\n",
              " 'sentence_embeddings': ['the soccer games will be postponed.'],\n",
              " 'cleanTokens': ['soccer', 'games', 'postponed'],\n",
              " 'token': ['the', 'soccer', 'games', 'will', 'be', 'postponed', '.'],\n",
              " 'class': ['Sports'],\n",
              " 'embeddings': ['soccer', 'game', 'postpone']}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "light_model.annotate('the soccer games will be postponed.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0xgbU0Gzqraz"
      },
      "source": [
        "# SentimentDL Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvQmF-X4sMYg"
      },
      "source": [
        "see also here >> `https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/SentimentDL_train_multiclass_sentiment_classifier.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "inuIcH5sq_5H"
      },
      "outputs": [],
      "source": [
        "!wget -q aclimdb_train.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_train.csv\n",
        "!wget -q aclimdb_test.csv https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/sentiment-corpus/aclimdb/aclimdb_test.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W1-7tMKnrFF2",
        "outputId": "965c4cbf-6580-4885-9bce-946a029cf9d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+\n",
            "|                          text|   label|\n",
            "+------------------------------+--------+\n",
            "|This is an Excellent little...|positive|\n",
            "|The Sarah Silverman program...|positive|\n",
            "|\"Prom Night\" is a title-onl...|negative|\n",
            "|So often a band will get to...|positive|\n",
            "|\"Pet Sematary\" is an adapta...|positive|\n",
            "|I watched the film recently...|negative|\n",
            "|Boy this movie had me foole...|negative|\n",
            "|Checking the spoiler alert ...|negative|\n",
            "|Despite its rather salaciou...|positive|\n",
            "|Absolute masterpiece of a f...|positive|\n",
            "|The tweedy professor-types ...|positive|\n",
            "|A movie best summed up by t...|negative|\n",
            "|Take young, pretty people, ...|negative|\n",
            "|For months I've been hearin...|negative|\n",
            "|\"Batman: The Mystery of the...|positive|\n",
            "|Well, it was funny in spots...|negative|\n",
            "|I have seen the short movie...|positive|\n",
            "|Brainless film about a good...|negative|\n",
            "|Leave it to geniuses like V...|negative|\n",
            "|Seven Pounds stars Will Smi...|positive|\n",
            "+------------------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "trainDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"aclimdb_train.csv\")\n",
        "\n",
        "trainDataset.show(truncate=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHVXJvW18g8i",
        "outputId": "16679927-5066-4084-f053-582fb6a023ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------------------------+--------+\n",
            "|                          text|   label|\n",
            "+------------------------------+--------+\n",
            "|The Second Woman is about t...|negative|\n",
            "|In my opinion the directing...|positive|\n",
            "|I am listening to Istanbul,...|positive|\n",
            "|Before I speak my piece, I ...|negative|\n",
            "|ManBearPig is a pretty funn...|positive|\n",
            "|A buddy and I went to see t...|negative|\n",
            "|It is incredible that there...|negative|\n",
            "|Dire! Dismal! Awful! Laugha...|negative|\n",
            "|HLOTS was an outstanding se...|positive|\n",
            "|This is just one of those f...|negative|\n",
            "|This movie had the potentia...|negative|\n",
            "|The 80s were overrun by all...|positive|\n",
            "|The tunes are the best aspe...|positive|\n",
            "|Having recently seen Grindh...|positive|\n",
            "|My favorite film this year....|positive|\n",
            "|This movie just might make ...|positive|\n",
            "|This is the worst movie I h...|negative|\n",
            "|This was a nice film. It ha...|positive|\n",
            "|I don't know, maybe I just ...|negative|\n",
            "|After wasting 2 hours of my...|negative|\n",
            "+------------------------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "testDataset = spark.read \\\n",
        "      .option(\"header\", True) \\\n",
        "      .csv(\"aclimdb_test.csv\")\n",
        "\n",
        "testDataset.show(truncate = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bhQyIKOqwZJ",
        "outputId": "5b3d7b3b-ae2f-4efd-dd8f-abae3e02ccda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tfhub_use_lg download started this may take some time.\n",
            "Approximate size to download 753.3 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# actual content is inside description column\n",
        "document = DocumentAssembler()\\\n",
        "    .setInputCol(\"text\")\\\n",
        "    .setOutputCol(\"document\")\n",
        "\n",
        "use = UniversalSentenceEncoder.pretrained(\"tfhub_use_lg\", \"en\") \\\n",
        "    .setInputCols(\"document\") \\\n",
        "    .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# the classes/labels/categories are in category column\n",
        "sentimentdl = SentimentDLApproach()\\\n",
        "    .setInputCols([\"sentence_embeddings\"])\\\n",
        "    .setOutputCol(\"class\")\\\n",
        "    .setLabelColumn(\"label\")\\\n",
        "    .setMaxEpochs(5)\\\n",
        "    .setEnableOutputLogs(True)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        use,\n",
        "        sentimentdl\n",
        "    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2nOxevkKrSC1",
        "outputId": "6c4ff015-7b92-4019-ccaf-14cc49230d0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 1.63 s, sys: 194 ms, total: 1.82 s\n",
            "Wall time: 6min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "pipelineModel = pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "t-wOcQkl8erj"
      },
      "outputs": [],
      "source": [
        "result = pipelineModel.transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "maHT9M0M9Cpf"
      },
      "outputs": [],
      "source": [
        "result_df = result.select('text','label',\"class.result\").toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "lSJs_oBkBxSd",
        "outputId": "0c50de17-4b05-4052-c0a2-cd036e71c254"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text     label      result\n",
              "0  The Second Woman is about the story of a myste...  negative  [positive]\n",
              "1  In my opinion the directing, editing, lighting...  positive  [positive]\n",
              "2  I am listening to Istanbul, intent, my eyes cl...  positive  [positive]\n",
              "3  Before I speak my piece, I would like to make ...  negative  [positive]\n",
              "4  ManBearPig is a pretty funny episode of South ...  positive  [positive]\n",
              "5  A buddy and I went to see this movie when it c...  negative  [negative]\n",
              "6  It is incredible that there were two films wit...  negative  [negative]\n",
              "7  Dire! Dismal! Awful! Laughable! Disappointing!...  negative  [negative]\n",
              "8  HLOTS was an outstanding series, its what NYPD...  positive  [positive]\n",
              "9  This is just one of those films which cannot j...  negative  [negative]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-691ca52c-729a-4260-b149-3425005eae30\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>The Second Woman is about the story of a myste...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In my opinion the directing, editing, lighting...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I am listening to Istanbul, intent, my eyes cl...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Before I speak my piece, I would like to make ...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ManBearPig is a pretty funny episode of South ...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>A buddy and I went to see this movie when it c...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>It is incredible that there were two films wit...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Dire! Dismal! Awful! Laughable! Disappointing!...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>HLOTS was an outstanding series, its what NYPD...</td>\n",
              "      <td>positive</td>\n",
              "      <td>[positive]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>This is just one of those films which cannot j...</td>\n",
              "      <td>negative</td>\n",
              "      <td>[negative]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-691ca52c-729a-4260-b149-3425005eae30')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-691ca52c-729a-4260-b149-3425005eae30 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-691ca52c-729a-4260-b149-3425005eae30');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "result_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "InbWSJgRrv5Z"
      },
      "source": [
        "# MultiLabel Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XW4BYeXAsIgn"
      },
      "source": [
        "see also here >> `https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/training/english/classification/MultiClassifierDL_train_multi_label_toxic_classifier.ipynb`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xso1Utygr29i",
        "outputId": "bc58bf7b-e16b-48a1-bca4-14c69718fda3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2702k  100 2702k    0     0  8606k      0 --:--:-- --:--:-- --:--:-- 8579k\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  289k  100  289k    0     0  2415k      0 --:--:-- --:--:-- --:--:-- 2415k\n"
          ]
        }
      ],
      "source": [
        "!curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_train.snappy.parquet'\n",
        "!curl -O 'https://s3.amazonaws.com/auxdata.johnsnowlabs.com/public/resources/en/classifier-dl/toxic_comments/toxic_test.snappy.parquet'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NwXFrp20r972"
      },
      "outputs": [],
      "source": [
        "trainDataset = spark.read.parquet(\"/content/toxic_train.snappy.parquet\").repartition(120)\n",
        "testDataset = spark.read.parquet(\"/content/toxic_test.snappy.parquet\").repartition(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4mRvjCZwXTC"
      },
      "source": [
        "## Multilabel Classifier with Bert Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_pakwy8iPxx3",
        "outputId": "441a3dbd-796d-4fa9-d71f-a04b548cb9be"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sent_small_bert_L8_512 download started this may take some time.\n",
            "Approximate size to download 149.1 MB\n",
            "[OK!]\n"
          ]
        }
      ],
      "source": [
        "# Let's use shrink to remove new lines in the comments\n",
        "document = DocumentAssembler()\\\n",
        "      .setInputCol(\"text\")\\\n",
        "      .setOutputCol(\"document\")\\\n",
        "      .setCleanupMode(\"shrink\")\n",
        "\n",
        "bert_sent = BertSentenceEmbeddings.pretrained('sent_small_bert_L8_512')\\\n",
        "      .setInputCols([\"document\"])\\\n",
        "      .setOutputCol(\"sentence_embeddings\")\n",
        "\n",
        "# We will use MultiClassifierDL built by using Bidirectional GRU and CNNs inside TensorFlow that supports up to 100 classes\n",
        "# We will use only 5 Epochs but feel free to increase it on your own dataset\n",
        "multiClassifier = MultiClassifierDLApproach()\\\n",
        "      .setInputCols(\"sentence_embeddings\")\\\n",
        "      .setOutputCol(\"category\")\\\n",
        "      .setLabelColumn(\"labels\")\\\n",
        "      .setBatchSize(128)\\\n",
        "      .setMaxEpochs(5)\\\n",
        "      .setLr(1e-3)\\\n",
        "      .setThreshold(0.5)\\\n",
        "      .setShufflePerEpoch(False)\\\n",
        "      .setEnableOutputLogs(True)\\\n",
        "      .setValidationSplit(0.1)\n",
        "\n",
        "pipeline = Pipeline(\n",
        "    stages = [\n",
        "        document,\n",
        "        bert_sent,\n",
        "        multiClassifier\n",
        "    ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZitAuDLtH1X3"
      },
      "outputs": [],
      "source": [
        "#! rm -r /root/annotator_logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5KvUpcDP0q1K",
        "outputId": "cb3c2623-3922-4657-d9e8-de5ec9a38271"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 681 ms, sys: 72.2 ms, total: 754 ms\n",
            "Wall time: 2min 24s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "pipelineModel = pipeline.fit(trainDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5gJ0iYySmYj",
        "outputId": "b0adc866-477d-434d-aaf5-acda4258dbd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training started - epochs: 5 - learning_rate: 0.001 - batch_size: 128 - training_examples: 13158 - classes: 6\n",
            "Epoch 0/5 - 10.73s - loss: 0.33723187 - acc: 0.8611509 - val_loss: 0.30032548 - val_acc: 0.8673656 - val_f1: 0.8026087 - val_tpr: 0.75142246 - batches: 103\n",
            "Epoch 1/5 - 1.09s - loss: 0.29930413 - acc: 0.8785859 - val_loss: 0.29365048 - val_acc: 0.86979216 - val_f1: 0.81163687 - val_tpr: 0.7816467 - batches: 103\n",
            "Epoch 2/5 - 1.19s - loss: 0.2917258 - acc: 0.8815477 - val_loss: 0.2913404 - val_acc: 0.87299633 - val_f1: 0.8172958 - val_tpr: 0.7914678 - batches: 103\n",
            "Epoch 3/5 - 1.08s - loss: 0.2864562 - acc: 0.8833028 - val_loss: 0.2905673 - val_acc: 0.8717741 - val_f1: 0.8149679 - val_tpr: 0.787109 - batches: 103\n",
            "Epoch 4/5 - 1.10s - loss: 0.28217906 - acc: 0.88537127 - val_loss: 0.29022342 - val_acc: 0.8730394 - val_f1: 0.81671864 - val_tpr: 0.78860056 - batches: 103\n"
          ]
        }
      ],
      "source": [
        "!cat ~/annotator_logs/{multiClassifier.uid}.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "f_kOty-Asgh0"
      },
      "outputs": [],
      "source": [
        "preds = pipelineModel.transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HHN17ojP_8-c"
      },
      "outputs": [],
      "source": [
        "preds_df = preds.select('text','labels',\"category.result\").toPandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "hPDnLmap0u0o",
        "outputId": "b6fc72b1-bdf8-4042-cf72-1f4e30242ae6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Vegan \\n\\nWhat in the hell does all that junk ...   \n",
              "1                     Fight Club! F**k Yeeaaaaahh!!!   \n",
              "2  \"\\n\\n Little quick on the trigger, ain't'cha b...   \n",
              "3  Your user page indicates you're a left-wing li...   \n",
              "4  \"  See all the many Google links, titled\"\" Wik...   \n",
              "5  \"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...   \n",
              "6  is it because it is of my naked mum having sex...   \n",
              "7  )\\na cowards site, that must stop changing thi...   \n",
              "8  blow me, criticism IS constructive. \\n\\nBlow m...   \n",
              "9  On account of the project deciding to ignore h...   \n",
              "\n",
              "                                              labels  \\\n",
              "0                                            [toxic]   \n",
              "1                                   [toxic, obscene]   \n",
              "2                                            [toxic]   \n",
              "3                           [toxic, obscene, insult]   \n",
              "4                                            [toxic]   \n",
              "5                                            [toxic]   \n",
              "6  [toxic, severe_toxic, obscene, insult, identit...   \n",
              "7                                   [toxic, obscene]   \n",
              "8                           [toxic, obscene, insult]   \n",
              "9                           [toxic, obscene, insult]   \n",
              "\n",
              "                                   result  \n",
              "0                        [toxic, obscene]  \n",
              "1                        [toxic, obscene]  \n",
              "2                                 [toxic]  \n",
              "3                                 [toxic]  \n",
              "4                                 [toxic]  \n",
              "5                        [toxic, obscene]  \n",
              "6  [toxic, severe_toxic, insult, obscene]  \n",
              "7                                 [toxic]  \n",
              "8                [toxic, insult, obscene]  \n",
              "9                                 [toxic]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c9a4ade2-3e3e-4e0d-92fa-134f6c39c98d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vegan \\n\\nWhat in the hell does all that junk ...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fight Club! F**k Yeeaaaaahh!!!</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"\\n\\n Little quick on the trigger, ain't'cha b...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Your user page indicates you're a left-wing li...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"  See all the many Google links, titled\"\" Wik...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>is it because it is of my naked mum having sex...</td>\n",
              "      <td>[toxic, severe_toxic, obscene, insult, identit...</td>\n",
              "      <td>[toxic, severe_toxic, insult, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>)\\na cowards site, that must stop changing thi...</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>blow me, criticism IS constructive. \\n\\nBlow m...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic, insult, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>On account of the project deciding to ignore h...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c9a4ade2-3e3e-4e0d-92fa-134f6c39c98d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c9a4ade2-3e3e-4e0d-92fa-134f6c39c98d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c9a4ade2-3e3e-4e0d-92fa-134f6c39c98d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "preds_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xN9YozVEw14g"
      },
      "source": [
        "## Saving & loading back the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hKkC3gtfvLkP",
        "outputId": "50a5d88d-fcb3-4e93-bc9d-215acce78093"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[DocumentAssembler_c7c521bd305d,\n",
              " BERT_SENTENCE_EMBEDDINGS_3608c0d843af,\n",
              " MultiClassifierDLModel_0dbf61fd7dbf]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "pipelineModel.stages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vfL95dDGu8i_"
      },
      "outputs": [],
      "source": [
        "# Save the Multilabel Classifier Model\n",
        "pipelineModel.stages[2].write().overwrite().save('MultilabelClfBert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "XBSvIjGCvagD"
      },
      "outputs": [],
      "source": [
        "# Load back  saved Multilabel Classifier Model\n",
        "MultilabelClfModel = MultiClassifierDLModel.load('MultilabelClfBert')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "LPkch64YwS1J"
      },
      "outputs": [],
      "source": [
        "# Generate prediction Pipeline with loaded Model \n",
        "ld_pipeline = Pipeline(stages=[document, bert_sent, MultilabelClfModel])\n",
        "ld_pipeline_model = ld_pipeline.fit(spark.createDataFrame([['']]).toDF(\"text\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "BNW3MLLHvzP5"
      },
      "outputs": [],
      "source": [
        "# Apply Model Transform to testData\n",
        "ld_preds = ld_pipeline_model.transform(testDataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "XF3Ik1uIwEmp"
      },
      "outputs": [],
      "source": [
        "ld_preds_df = ld_preds.select('text','labels',\"category.result\").toPandas()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "eRWA4OklzbbY",
        "outputId": "6f057bd0-5f4d-4ea4-de20-deb59fd75070"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  Vegan \\n\\nWhat in the hell does all that junk ...   \n",
              "1                     Fight Club! F**k Yeeaaaaahh!!!   \n",
              "2  \"\\n\\n Little quick on the trigger, ain't'cha b...   \n",
              "3  Your user page indicates you're a left-wing li...   \n",
              "4  \"  See all the many Google links, titled\"\" Wik...   \n",
              "5  \"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...   \n",
              "6  is it because it is of my naked mum having sex...   \n",
              "7  )\\na cowards site, that must stop changing thi...   \n",
              "8  blow me, criticism IS constructive. \\n\\nBlow m...   \n",
              "9  On account of the project deciding to ignore h...   \n",
              "\n",
              "                                              labels  \\\n",
              "0                                            [toxic]   \n",
              "1                                   [toxic, obscene]   \n",
              "2                                            [toxic]   \n",
              "3                           [toxic, obscene, insult]   \n",
              "4                                            [toxic]   \n",
              "5                                            [toxic]   \n",
              "6  [toxic, severe_toxic, obscene, insult, identit...   \n",
              "7                                   [toxic, obscene]   \n",
              "8                           [toxic, obscene, insult]   \n",
              "9                           [toxic, obscene, insult]   \n",
              "\n",
              "                                   result  \n",
              "0                        [toxic, obscene]  \n",
              "1                        [toxic, obscene]  \n",
              "2                                 [toxic]  \n",
              "3                                 [toxic]  \n",
              "4                                 [toxic]  \n",
              "5                        [toxic, obscene]  \n",
              "6  [toxic, severe_toxic, insult, obscene]  \n",
              "7                                 [toxic]  \n",
              "8                [toxic, insult, obscene]  \n",
              "9                                 [toxic]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d271e723-d4e5-4c1a-b9bb-9113059f0972\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>labels</th>\n",
              "      <th>result</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Vegan \\n\\nWhat in the hell does all that junk ...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fight Club! F**k Yeeaaaaahh!!!</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>\"\\n\\n Little quick on the trigger, ain't'cha b...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Your user page indicates you're a left-wing li...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\"  See all the many Google links, titled\"\" Wik...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>\"\\n\\n LOL \\n\\nLOL. Seriously, \"\"BryanFromPalat...</td>\n",
              "      <td>[toxic]</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>is it because it is of my naked mum having sex...</td>\n",
              "      <td>[toxic, severe_toxic, obscene, insult, identit...</td>\n",
              "      <td>[toxic, severe_toxic, insult, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>)\\na cowards site, that must stop changing thi...</td>\n",
              "      <td>[toxic, obscene]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>blow me, criticism IS constructive. \\n\\nBlow m...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic, insult, obscene]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>On account of the project deciding to ignore h...</td>\n",
              "      <td>[toxic, obscene, insult]</td>\n",
              "      <td>[toxic]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d271e723-d4e5-4c1a-b9bb-9113059f0972')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d271e723-d4e5-4c1a-b9bb-9113059f0972 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d271e723-d4e5-4c1a-b9bb-9113059f0972');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "ld_preds_df.head(10)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "6.Text_Classification_with_ClassifierDL.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
