{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v8xIEZ07QpRM",
    "outputId": "b5f5db4b-bce4-4b62-883f-3b3e90a3f1cd"
   },
   "source": [
    "![JohnSnowLabs](https://nlp.johnsnowlabs.com/assets/images/logo.png)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/JohnSnowLabs/spark-nlp-workshop/blob/master/jupyter/prediction/english/ViTForImageClassification.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget https://setup.johnsnowlabs.com/colab.sh -O - | bash /dev/stdin -p 3.2.1 -s 4.1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6KvNW4MU5rrF",
    "outputId": "36cf722b-f3a6-4566-8217-615cc58dc549"
   },
   "source": [
    "## ViTForImageClassification Annotator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebok we are going to classify images using spark-nlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FaN1OWV0NQ5T"
   },
   "source": [
    "### Downloading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "jEHkswUjUfaU"
   },
   "outputs": [],
   "source": [
    "!mkdir images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "k9F8WstLNXnS"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "spark_nlp_repo = \"https://raw.githubusercontent.com/JohnSnowLabs/spark-nlp\"\n",
    "image_resources = spark_nlp_repo + \"/master/image-classification-vit/src/test/resources/image/\"\n",
    "images = [\"bluetick.jpg\", \"tractor.JPEG\", \"chihuahua.jpg\", \"palace.JPEG\",\n",
    "          \"hippopotamus.JPEG\", \"hen.JPEG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "qkaXeDV2NbU6"
   },
   "outputs": [],
   "source": [
    "for image in images:\n",
    "    image_uri = image_resources + image\n",
    "    response = requests.get(image_uri)\n",
    "    open(\"./images/\" + image, 'wb').write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "XLNO3Z9r6HgR"
   },
   "outputs": [],
   "source": [
    "import sparknlp\n",
    "from sparknlp.base import *\n",
    "from sparknlp.annotator import *\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4JfeD8Rj-as2",
    "outputId": "dffe5e89-4130-4262-ea4b-5877b2851d60"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apache Spark version: 3.0.2\n"
     ]
    }
   ],
   "source": [
    "spark = sparknlp.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "99AqJEThSBuT"
   },
   "outputs": [],
   "source": [
    "data_df = spark.read.format(\"image\") \\\n",
    "            .load(path=\"images/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J86YU794UYEG"
   },
   "source": [
    "### Pipeline with ViTForImageClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tRyju8D-6XJ1",
    "outputId": "ac89dd9d-485a-4f44-a913-228fc8a6e2db"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image_classifier_vit_base_patch16_224 download started this may take some time.\n",
      "Approximate size to download 309.7 MB\n",
      "[OK!]\n"
     ]
    }
   ],
   "source": [
    "image_assembler = ImageAssembler() \\\n",
    "            .setInputCol(\"image\") \\\n",
    "            .setOutputCol(\"image_assembler\")\n",
    "\n",
    "image_classifier = ViTForImageClassification \\\n",
    "    .pretrained() \\\n",
    "    .setInputCols(\"image_assembler\") \\\n",
    "    .setOutputCol(\"class\")\n",
    "\n",
    "pipeline = Pipeline(stages=[\n",
    "    image_assembler,\n",
    "    image_classifier,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "XIYjEhW3O_Uc"
   },
   "outputs": [],
   "source": [
    "model = pipeline.fit(data_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gIZFLaUOPBnd",
    "outputId": "04e9a89e-b5a8-4c7f-cf57-5a013ae85700"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|               image|     image_assembler|               class|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|[file:///content/...|[[image, file:///...|[[category, 0, 5,...|\n",
      "|[file:///content/...|[[image, file:///...|[[category, 0, 55...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "image_df = model.transform(data_df)\n",
    "image_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rfp5MK1UxoNt"
   },
   "source": [
    "### Light Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-_6VJPS9xvfV"
   },
   "source": [
    "To use light pipeline in ViT transformer, we need to use the new method `fullAnnotateImage`, which can receive 3 kind of inputs:\n",
    "1. A path to a single image\n",
    "2. A path to a list of images\n",
    "3. A path to a directory of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XDQ6PrgbSJ8W",
    "outputId": "a1a153ba-6b32-4e72-88d2-c47ed2bb91c1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_assembler', 'class'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "light_pipeline = LightPipeline(model)\n",
    "annotations_result = light_pipeline.fullAnnotateImage(\"images/hippopotamus.JPEG\")\n",
    "annotations_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73PV--LdSU5-",
    "outputId": "cd3c1df7-0eb7-4409-a130-782ba020e982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "annotator_type: image\n",
      "origin: images/hippopotamus.JPEG\n",
      "height: 333\n",
      "width: 500\n",
      "nChannels: 3\n",
      "mode: 16\n",
      "result size: 499500\n",
      "metadata: Map()\n",
      "[Annotation(category, 0, 55, hippopotamus, hippo, river horse, Hippopotamus amphibius, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 7.2882756E-8, Some(beer glass) -> 9.0488925E-8, image -> 0, Some(damselfly) -> 1.9379786E-7, Some(turnstile) -> 6.8434524E-8, Some(cockroach, roach) -> 1.6622849E-7, height -> 333, Some(bulbul) -> 1.6930231E-7, Some(sea snake) -> 8.89582E-8, origin -> images/hippopotamus.JPEG, Some(mixing bowl) -> 1.2995402E-7, mode -> 16, None -> 1.3814622E-7, Some(whippet) -> 3.894023E-8, width -> 500, Some(buckle) -> 1.0061492E-7))]\n"
     ]
    }
   ],
   "source": [
    "for result in annotations_result:\n",
    "  image_assembler = result['image_assembler'][0]\n",
    "  print(f\"annotator_type: {image_assembler.annotator_type}\")\n",
    "  print(f\"origin: {image_assembler.origin}\")\n",
    "  print(f\"height: {image_assembler.height}\")\n",
    "  print(f\"width: {image_assembler.width}\")\n",
    "  print(f\"nChannels: {image_assembler.nChannels}\")\n",
    "  print(f\"mode: {image_assembler.mode}\")\n",
    "  print(f\"result size: {str(len(image_assembler.result))}\")\n",
    "  print(f\"metadata: {image_assembler.metadata}\")\n",
    "  print(result['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V37k8GQFySRW"
   },
   "source": [
    "To send a list of images, we just difine a set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "asf3MZGzyXl5",
    "outputId": "cec40441-d82b-42b2-b5e8-93dfdbd80b6a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_assembler', 'class'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = [\"images/bluetick.jpg\", \"images/palace.JPEG\", \"images/hen.JPEG\"]\n",
    "annotations_result = light_pipeline.fullAnnotateImage(images)\n",
    "annotations_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dfby3MJlymNV",
    "outputId": "d32f0b99-d13c-47b9-c459-b4504b1d0aa4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Annotation(category, 0, 7, bluetick, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 1.3846728E-6, Some(beer glass) -> 1.1807944E-6, image -> 0, Some(damselfly) -> 3.6875622E-7, Some(turnstile) -> 2.023695E-6, Some(cockroach, roach) -> 6.2982855E-7, height -> 500, Some(bulbul) -> 5.417509E-7, Some(sea snake) -> 5.7421556E-7, origin -> images/bluetick.jpg, Some(mixing bowl) -> 5.4001305E-7, mode -> 16, None -> 4.5454306E-7, Some(whippet) -> 1.2101438E-6, width -> 333, Some(buckle) -> 1.1306514E-6))]\n",
      "[Annotation(category, 0, 5, palace, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 6.3918545E-5, Some(beer glass) -> 8.879939E-6, image -> 0, Some(damselfly) -> 9.565577E-6, Some(turnstile) -> 6.315168E-5, Some(cockroach, roach) -> 1.125408E-5, height -> 334, Some(bulbul) -> 3.321073E-5, Some(sea snake) -> 1.0886038E-5, origin -> images/palace.JPEG, Some(mixing bowl) -> 2.6202975E-5, mode -> 16, None -> 2.6134943E-5, Some(whippet) -> 1.3805137E-5, width -> 500, Some(buckle) -> 3.121459E-5))]\n",
      "[Annotation(category, 0, 2, hen, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 2.1663836E-5, Some(beer glass) -> 3.062036E-6, image -> 0, Some(damselfly) -> 5.8477954E-6, Some(turnstile) -> 1.8546416E-6, Some(cockroach, roach) -> 2.5356887E-6, height -> 375, Some(bulbul) -> 3.2049334E-6, Some(sea snake) -> 2.8824059E-6, origin -> images/hen.JPEG, Some(mixing bowl) -> 6.9148127E-6, mode -> 16, None -> 2.824775E-6, Some(whippet) -> 4.5998115E-7, width -> 500, Some(buckle) -> 1.6334545E-5))]\n"
     ]
    }
   ],
   "source": [
    "for result in annotations_result:\n",
    "  print(result['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gYvm6Geyync6"
   },
   "source": [
    "Or we can simply send a directory that contains all the images we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tnh6Auowym-A",
    "outputId": "36c9c411-1359-4f25-c602-99c523130847"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['image_assembler', 'class'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotations_result = light_pipeline.fullAnnotateImage(\"images/\")\n",
    "annotations_result[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R01hdxNey12y",
    "outputId": "03a39fa5-d7bb-4a7a-afb4-1acef0b3e304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Annotation(category, 0, 8, Chihuahua, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 2.093878E-7, Some(beer glass) -> 2.577504E-7, image -> 0, Some(damselfly) -> 7.065122E-8, Some(turnstile) -> 5.03293E-7, Some(cockroach, roach) -> 4.3412697E-7, height -> 500, Some(bulbul) -> 3.4132438E-7, Some(sea snake) -> 1.5207818E-6, origin -> images/chihuahua.jpg, Some(mixing bowl) -> 2.208622E-7, mode -> 16, None -> 3.1694032E-7, Some(whippet) -> 1.1523372E-5, width -> 333, Some(buckle) -> 3.492674E-6))]\n",
      "[Annotation(category, 0, 55, hippopotamus, hippo, river horse, Hippopotamus amphibius, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 7.2882756E-8, Some(beer glass) -> 9.0488925E-8, image -> 0, Some(damselfly) -> 1.9379786E-7, Some(turnstile) -> 6.8434524E-8, Some(cockroach, roach) -> 1.6622849E-7, height -> 333, Some(bulbul) -> 1.6930231E-7, Some(sea snake) -> 8.89582E-8, origin -> images/hippopotamus.JPEG, Some(mixing bowl) -> 1.2995402E-7, mode -> 16, None -> 1.3814622E-7, Some(whippet) -> 3.894023E-8, width -> 500, Some(buckle) -> 1.0061492E-7))]\n",
      "[Annotation(category, 0, 2, hen, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 2.1663836E-5, Some(beer glass) -> 3.062036E-6, image -> 0, Some(damselfly) -> 5.8477954E-6, Some(turnstile) -> 1.8546416E-6, Some(cockroach, roach) -> 2.5356887E-6, height -> 375, Some(bulbul) -> 3.2049334E-6, Some(sea snake) -> 2.8824059E-6, origin -> images/hen.JPEG, Some(mixing bowl) -> 6.9148127E-6, mode -> 16, None -> 2.824775E-6, Some(whippet) -> 4.5998115E-7, width -> 500, Some(buckle) -> 1.6334545E-5))]\n",
      "[Annotation(category, 0, 6, tractor, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 4.1058443E-5, Some(beer glass) -> 1.3166338E-6, image -> 0, Some(damselfly) -> 2.3266741E-6, Some(turnstile) -> 1.6458862E-5, Some(cockroach, roach) -> 1.48074E-6, height -> 174, Some(bulbul) -> 1.0093752E-6, Some(sea snake) -> 1.4689642E-6, origin -> images/tractor.JPEG, Some(mixing bowl) -> 1.3967011E-6, mode -> 16, None -> 1.9897216E-6, Some(whippet) -> 1.2082123E-6, width -> 250, Some(buckle) -> 6.0837033E-6))]\n",
      "[Annotation(category, 0, 5, palace, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 6.3918545E-5, Some(beer glass) -> 8.879939E-6, image -> 0, Some(damselfly) -> 9.565577E-6, Some(turnstile) -> 6.315168E-5, Some(cockroach, roach) -> 1.125408E-5, height -> 334, Some(bulbul) -> 3.321073E-5, Some(sea snake) -> 1.0886038E-5, origin -> images/palace.JPEG, Some(mixing bowl) -> 2.6202975E-5, mode -> 16, None -> 2.6134943E-5, Some(whippet) -> 1.3805137E-5, width -> 500, Some(buckle) -> 3.121459E-5))]\n",
      "[Annotation(category, 0, 7, bluetick, Map(nChannels -> 3, Some(lumbermill, sawmill) -> 1.3846728E-6, Some(beer glass) -> 1.1807944E-6, image -> 0, Some(damselfly) -> 3.6875622E-7, Some(turnstile) -> 2.023695E-6, Some(cockroach, roach) -> 6.2982855E-7, height -> 500, Some(bulbul) -> 5.417509E-7, Some(sea snake) -> 5.7421556E-7, origin -> images/bluetick.jpg, Some(mixing bowl) -> 5.4001305E-7, mode -> 16, None -> 4.5454306E-7, Some(whippet) -> 1.2101438E-6, width -> 333, Some(buckle) -> 1.1306514E-6))]\n"
     ]
    }
   ],
   "source": [
    "for result in annotations_result:\n",
    "  print(result['class'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "ViTForImageClassification-LightPipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
